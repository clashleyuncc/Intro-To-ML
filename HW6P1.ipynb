{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrHvgnraj0wbmQtxABi3c5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clashleyuncc/Intro-To-ML/blob/main/HW6P1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMCsF6At4IRF",
        "outputId": "f6377c74-fa05-43cf-807a-2741519217dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 25622359310336.0000, Validation loss 28579731603456.0000\n",
            "Training Time: 0.03862428665161133 seconds\n",
            "Epoch 1000, Training loss 18868292550656.0000, Validation loss 21541754503168.0000\n",
            "Training Time: 2.0497889518737793 seconds\n",
            "Epoch 2000, Training loss 14145338474496.0000, Validation loss 16581155356672.0000\n",
            "Training Time: 4.197384834289551 seconds\n",
            "Epoch 3000, Training loss 10850344632320.0000, Validation loss 13087668174848.0000\n",
            "Training Time: 6.109996795654297 seconds\n",
            "Epoch 4000, Training loss 8551580827648.0000, Validation loss 10623111921664.0000\n",
            "Training Time: 7.588721513748169 seconds\n",
            "Epoch 5000, Training loss 6947841507328.0000, Validation loss 8880892411904.0000\n",
            "Training Time: 9.077118158340454 seconds\n"
          ]
        }
      ],
      "source": [
        "#use gpu?\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import OrderedDict\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val,\n",
        "                  t_c_train, t_c_val):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        t_p_train = model(t_u_train)\n",
        "        loss_train = loss_fn(t_p_train, t_c_train)\n",
        "\n",
        "        t_p_val = model(t_u_val)\n",
        "        loss_val = loss_fn(t_p_val, t_c_val)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch == 1 or epoch % 1000 == 0:\n",
        "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
        "                  f\" Validation loss {loss_val.item():.4f}\")\n",
        "            print(f\"Training Time: {time.time()-start_time} seconds\")\n",
        "\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "file_path = '/content/drive/My Drive/4th Year Charlotte/IntroToML/Housing.csv'\n",
        "\n",
        "housing = pd.read_csv(file_path)\n",
        "\n",
        "varlist =  ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
        "\n",
        "def binary_map(x):\n",
        "    return x.map({'yes': 1, 'no': 0})\n",
        "\n",
        "housing[varlist] = housing[varlist].apply(binary_map)\n",
        "\n",
        "Y = housing.pop('price')\n",
        "X = housing[['area', 'bedrooms', 'bathrooms', 'stories', 'parking', 'mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning']]\n",
        "\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "Ytarget = pd.DataFrame(Y)\n",
        "\n",
        "#print(X.mean(axis=0), X.std(axis=0))\n",
        "\n",
        "t_c = Y\n",
        "t_u = X\n",
        "t_c = torch.tensor(t_c)\n",
        "t_u = torch.tensor(t_u)\n",
        "\n",
        "t_u = t_u.to(torch.float32)\n",
        "t_c = t_c.to(torch.float32)\n",
        "\n",
        "n_samples = t_u.shape[0]\n",
        "n_val = int(0.2 * n_samples)\n",
        "shuffled_indices = torch.randperm(n_samples)\n",
        "train_indices = shuffled_indices[:-n_val]\n",
        "val_indices = shuffled_indices[-n_val:]\n",
        "t_u_train = t_u[train_indices]\n",
        "t_c_train = t_c[train_indices]\n",
        "t_u_val = t_u[val_indices]\n",
        "t_c_val = t_c[val_indices]\n",
        "t_un_train = 0.1 * t_u_train\n",
        "t_un_val = 0.1 * t_u_val\n",
        "\n",
        "seq_model = nn.Sequential(OrderedDict([\n",
        "            ('hidden_linear', nn.Linear(10, 8)),\n",
        "            ('hidden_activation', nn.Tanh()),\n",
        "            ('output_linear', nn.Linear(8,1))\n",
        "]))\n",
        "\n",
        "optimizer = optim.SGD(seq_model.parameters(), lr=1e-5)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = optimizer,\n",
        "    model = seq_model,\n",
        "    loss_fn = nn.MSELoss(),\n",
        "    t_u_train = t_un_train,\n",
        "    t_u_val = t_un_val,\n",
        "    t_c_train = t_c_train,\n",
        "    t_c_val = t_c_val)\n",
        "\n"
      ]
    }
  ]
}