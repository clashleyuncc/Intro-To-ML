{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNLLwScgHH0ycgzhe/W464o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clashleyuncc/Intro-To-ML/blob/main/HW7P1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P1a\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import OrderedDict\n",
        "from torchvision import datasets\n",
        "import time\n",
        "import datetime\n",
        "start_time = time.time()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "data_path = '../data-unversioned/p1ch7/'\n",
        "cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
        "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)\n",
        "\n",
        "#use relu\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "    #self.act1 = nn.Tanh()\n",
        "    #self.pool1 = nn.MaxPool2d(2)\n",
        "    self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "    #self.act2 = nn.Tanh()\n",
        "    #self.pool2 = nn.MaxPool2d(2)\n",
        "    self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "    #self.act3 = nn.Tanh()\n",
        "    self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "    out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "    out = out.view(-1, 8 * 8 * 8)\n",
        "    #out = self.act3(self.fcl(out))\n",
        "    out = torch.tanh(self.fc1(out))\n",
        "    out = self.fc2(out)\n",
        "    return out\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "    loss_train = 0.0\n",
        "    for imgs, labels in train_loader:\n",
        "      imgs = imgs.to(device=device)\n",
        "      labels = labels.to(device=device)\n",
        "      #batch_size = imgs.shape[0]\n",
        "      outputs = model(imgs)\n",
        "      loss = loss_fn(outputs, labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      loss_train += loss.item()\n",
        "    if epoch == 1 or epoch % 10 == 0:\n",
        "      print('{} Seconds, Epoch {}, Training Loss {}'.format(\n",
        "          time.time()-start_time, epoch,\n",
        "          loss_train / len(train_loader)))\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "tensor_cifar10 = datasets.CIFAR10(data_path, train=True, download=False,\n",
        "                                  transform=transforms.ToTensor())\n",
        "tensor_cifar10_val = datasets.CIFAR10(data_path, train=False, download=False,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "#transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))\n",
        "\n",
        "transformed_cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=False,\n",
        "    transform = transforms.Compose([\n",
        "       transforms.ToTensor(),\n",
        "       transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                            (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "\n",
        "tensor_cifar10 = transformed_cifar10\n",
        "\n",
        "model = Net().to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(tensor_cifar10, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "  for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "      imgs, labels = imgs.to(device), labels.to(device)\n",
        "      #batch_size = imgs.shape[0]\n",
        "      outputs = model(imgs)\n",
        "      _, predicted = torch.max(outputs, dim=1)\n",
        "      total += labels.shape[0]\n",
        "      correct += int((predicted == labels).sum())\n",
        "  print(\"Accuracy {}: {:.2f}\".format(name, correct/total))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(tensor_cifar10, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(tensor_cifar10_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "validate(model, train_loader, val_loader)\n",
        "\n",
        "print(f\"Training Time: {time.time()-start_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8984YUouytOQ",
        "outputId": "cff3b464-e727-4bf7-b935-1264afd7c797"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "18.630839109420776 Seconds, Epoch 1, Training Loss 2.0113122336699836\n",
            "155.84064602851868 Seconds, Epoch 10, Training Loss 1.1837053300474611\n",
            "307.9122862815857 Seconds, Epoch 20, Training Loss 1.025008982633386\n",
            "459.5819447040558 Seconds, Epoch 30, Training Loss 0.9488099751722477\n",
            "611.169219493866 Seconds, Epoch 40, Training Loss 0.8970924707324913\n",
            "762.1090159416199 Seconds, Epoch 50, Training Loss 0.8549329160957995\n",
            "913.7026898860931 Seconds, Epoch 60, Training Loss 0.8180795456366161\n",
            "1065.7020633220673 Seconds, Epoch 70, Training Loss 0.7878165613583592\n",
            "1216.7174150943756 Seconds, Epoch 80, Training Loss 0.7626468076577881\n",
            "1367.6278977394104 Seconds, Epoch 90, Training Loss 0.7392629329353342\n",
            "1518.490958929062 Seconds, Epoch 100, Training Loss 0.71673204443034\n",
            "Accuracy (): (:.2f)\n",
            "Training Time: 1520.049735069275 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P1b\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import OrderedDict\n",
        "from torchvision import datasets\n",
        "import time\n",
        "import datetime\n",
        "start_time = time.time()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "data_path = '../data-unversioned/p1ch7/'\n",
        "cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
        "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)\n",
        "\n",
        "#use relu\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "    self.act1 = nn.Tanh()\n",
        "    self.pool1 = nn.MaxPool2d(2)\n",
        "    self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "    self.act2 = nn.Tanh()\n",
        "    self.pool2 = nn.MaxPool2d(2)\n",
        "    self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "    self.act3 = nn.Tanh()\n",
        "    self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "    out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "    out = out.view(-1, 8 * 8 * 8)\n",
        "    out = self.act3(self.fcl(out))\n",
        "    out = torch.tanh(self.fc1(out))\n",
        "    out = self.fc2(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "    loss_train = 0.0\n",
        "    for imgs, labels in train_loader:\n",
        "      imgs = imgs.to(device=device)\n",
        "      labels = labels.to(device=device)\n",
        "      #batch_size = imgs.shape[0]\n",
        "      outputs = model(imgs)\n",
        "      loss = loss_fn(outputs, labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      loss_train += loss.item()\n",
        "    if epoch == 1 or epoch % 10 == 0:\n",
        "      print('{} Seconds, Epoch {}, Training Loss {}'.format(\n",
        "          time.time()-start_time, epoch,\n",
        "          loss_train / len(train_loader)))\n",
        "\n",
        "#from torchvision import transforms\n",
        "\n",
        "tensor_cifar10 = datasets.CIFAR10(data_path, train=True, download=False,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "#transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))\n",
        "\n",
        "transformed_cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=False,\n",
        "    transform = transforms.Compose([\n",
        "       transforms.ToTensor(),\n",
        "       transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                            (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "\n",
        "#model.to(device)\n",
        "model = Net()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(tensor_cifar10, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "  for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "      #imgs, labels = imgs.to(device), labels.to(device)\n",
        "      #batch_size = imgs.shape[0]\n",
        "      outputs = model(imgs)\n",
        "      _, predicted = torch.max(outputs, dim=1)\n",
        "      total += labels.shape[0]\n",
        "      correct += int((predicted == labels).sum())\n",
        "  print(\"Accuracy (): (:.2f)\".format(name, correct/total))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "validate(model, train_loader, val_loader)\n",
        "\n",
        "print(f\"Training Time: {time.time()-start_time} seconds\")"
      ],
      "metadata": {
        "id": "jUjm-frPbjgI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
