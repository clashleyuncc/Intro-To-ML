{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMicn5w45ylXmVUbaeN+o4B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clashleyuncc/Intro-To-ML/blob/main/HW7P1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P1a\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import OrderedDict\n",
        "from torchvision import datasets\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "data_path = '../data-unversioned/p1ch7/'\n",
        "cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
        "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "    self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "    self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "    out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
        "    out = out.view(-1, 8 * 8 * 8)\n",
        "    out = torch.relu(self.fc1(out))\n",
        "    out = self.fc2(out)\n",
        "    return out\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "    loss_train = 0.0\n",
        "    for imgs, labels in train_loader:\n",
        "      imgs = imgs.to(device=device)\n",
        "      labels = labels.to(device=device)\n",
        "      outputs = model(imgs)\n",
        "      loss = loss_fn(outputs, labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      loss_train += loss.item()\n",
        "    if epoch == 1 or epoch % 10 == 0:\n",
        "      print('{} Seconds, Epoch {}, Training Loss {}'.format(\n",
        "          time.time()-start_time, epoch,\n",
        "          loss_train / len(train_loader)))\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "tensor_cifar10 = datasets.CIFAR10(data_path, train=True, download=False,\n",
        "                                  transform=transforms.ToTensor())\n",
        "tensor_cifar10_val = datasets.CIFAR10(data_path, train=False, download=False,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "transformed_cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=False,\n",
        "    transform = transforms.Compose([\n",
        "       transforms.ToTensor(),\n",
        "       transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                            (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "\n",
        "tensor_cifar10 = transformed_cifar10\n",
        "\n",
        "model = Net().to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(tensor_cifar10, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 200,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "  for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "      imgs, labels = imgs.to(device), labels.to(device)\n",
        "      outputs = model(imgs)\n",
        "      _, predicted = torch.max(outputs, dim=1)\n",
        "      total += labels.shape[0]\n",
        "      correct += int((predicted == labels).sum())\n",
        "  print(\"Accuracy {}: {:.2f}\".format(name, correct/total))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(tensor_cifar10, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(tensor_cifar10_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "validate(model, train_loader, val_loader)\n",
        "\n",
        "print(f\"Training Time: {time.time()-start_time} seconds\")\n",
        "print(f\"Approximatly: {round((time.time()-start_time)/60,3)} minutes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8984YUouytOQ",
        "outputId": "4a9164f7-3b65-4c9f-fd2f-eebfaddeca59"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "17.058840036392212 Seconds, Epoch 1, Training Loss 2.1038315774839553\n",
            "146.30653476715088 Seconds, Epoch 10, Training Loss 1.1588254480258278\n",
            "287.3507544994354 Seconds, Epoch 20, Training Loss 0.9889371754873134\n",
            "430.0442945957184 Seconds, Epoch 30, Training Loss 0.8991482885521086\n",
            "574.4116680622101 Seconds, Epoch 40, Training Loss 0.8426430898782847\n",
            "719.4079780578613 Seconds, Epoch 50, Training Loss 0.8006435016079632\n",
            "866.299289226532 Seconds, Epoch 60, Training Loss 0.7685819520517383\n",
            "1011.2978353500366 Seconds, Epoch 70, Training Loss 0.7445325304937485\n",
            "1154.0327427387238 Seconds, Epoch 80, Training Loss 0.7226013745112188\n",
            "1300.1680233478546 Seconds, Epoch 90, Training Loss 0.7038538263505681\n",
            "1443.309053182602 Seconds, Epoch 100, Training Loss 0.6870795959401923\n",
            "1584.1518199443817 Seconds, Epoch 110, Training Loss 0.6703655754818636\n",
            "1727.0590357780457 Seconds, Epoch 120, Training Loss 0.6598106324291595\n",
            "1871.9306392669678 Seconds, Epoch 130, Training Loss 0.6497098036358119\n",
            "2012.331104516983 Seconds, Epoch 140, Training Loss 0.636006683720957\n",
            "2154.6563861370087 Seconds, Epoch 150, Training Loss 0.6267752312790708\n",
            "2295.155657529831 Seconds, Epoch 160, Training Loss 0.6204533548763645\n",
            "2434.5611600875854 Seconds, Epoch 170, Training Loss 0.6112966652950058\n",
            "2573.5890119075775 Seconds, Epoch 180, Training Loss 0.6017985923210983\n",
            "2713.159523487091 Seconds, Epoch 190, Training Loss 0.5964314557249893\n",
            "2852.264879465103 Seconds, Epoch 200, Training Loss 0.5901373265039586\n",
            "Accuracy val: 0.21\n",
            "Training Time: 2854.3691132068634 seconds\n",
            "Approximatly: 47.573 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P1b\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import OrderedDict\n",
        "from torchvision import datasets\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "data_path = '../data-unversioned/p1ch7/'\n",
        "cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
        "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "    self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "    self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "    out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
        "    out = out.view(-1, 8 * 8 * 8)\n",
        "    out = torch.relu(self.fc1(out))\n",
        "    out = self.fc2(out)\n",
        "    return out\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "    loss_train = 0.0\n",
        "    for imgs, labels in train_loader:\n",
        "      imgs = imgs.to(device=device)\n",
        "      labels = labels.to(device=device)\n",
        "      outputs = model(imgs)\n",
        "      loss = loss_fn(outputs, labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      loss_train += loss.item()\n",
        "    if epoch == 1 or epoch % 10 == 0:\n",
        "      print('{} Seconds, Epoch {}, Training Loss {}'.format(\n",
        "          time.time()-start_time, epoch,\n",
        "          loss_train / len(train_loader)))\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "tensor_cifar10 = datasets.CIFAR10(data_path, train=True, download=False,\n",
        "                                  transform=transforms.ToTensor())\n",
        "tensor_cifar10_val = datasets.CIFAR10(data_path, train=False, download=False,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "transformed_cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=False,\n",
        "    transform = transforms.Compose([\n",
        "       transforms.ToTensor(),\n",
        "       transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                            (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "\n",
        "tensor_cifar10 = transformed_cifar10\n",
        "\n",
        "model = Net().to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(tensor_cifar10, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 200,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "  for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for imgs, labels in val_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "    print(\"Accuracy {}: {:.2f}\".format(name, correct/total))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(tensor_cifar10, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(tensor_cifar10_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "validate(model, train_loader, val_loader)\n",
        "\n",
        "print(f\"Training Time: {time.time()-start_time} seconds\")\n",
        "print(f\"Approximatly: {round((time.time()-start_time)/60,3)} minutes\")\n"
      ],
      "metadata": {
        "id": "jUjm-frPbjgI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}